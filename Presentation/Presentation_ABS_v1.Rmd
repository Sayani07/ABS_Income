
---
title: Implementation of LISA - Variation  of Income across different LGAs in Australia 
date: May 9, 2018
output: beamer_presentation
---

#Why Spatial Econometrics

*Everything is related to everything else, but near things are more related than distant things*   
**Tobler's (1979) first law of geagraphy**

- Spatial Dependence : Existemce of functional relationship between what happens at one point in      space and what happens elsewhere
- Spatial Heterogeneity: lack of uniformity of effect of space
Example: Urban places have unequal population and income levels

#Why Spatial Econometrics

##Neighbors in Space

Expressing a way the structure of spatial dependence is to be incorporated in a model

- Lagged variable in time series analysis is unambiguous
- Spatial Lag?
- Neighborhood and nearest neighbor
{j | P([x_i])$\neq$ P[x_i|x_j] and d_ij < \(\epsilon\)}

#Why Spatial Econometrics

##Spatial Contiguity Matrices

- Binary Contiguity Matrix
- Rook Contiguity: sides
- Bishop Contiguity: corners
- Queen Contiguity sides and corners

For irregularly spaced grid, determination of contiguity is not unique 

- Distance Based Weights

- K-nearest neighbor weights


#From where did we get the Data

##Income Data Source

- Australian Bureau Of Statistics (http://stat.data.abs.gov.au) 
- Economy -> Finance -> Household Income -> Census 2016, Total Household Income (Weekly) by    Household Composition (LGA)
- Customise layout():   
Page -  Census Year, Household Composition  
Row - State, Region, Geography Level  
Column - Total Household Income Weekly 

#From where did we get the Data  

##Shapefile Data Source

- Australian Bureau Of Statistics (http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.003July%202016?OpenDocument)

- Name of the file (Zip) to download: Local Government Areas ASGS Ed 2016 Digital Boundaries in ESRI Shapefile Format 

#How does the Data look
```{r setup, include=FALSE,}
library(dplyr)
library(magrittr)
library(knitr)
library(readr)
library(ggplot2)
library(spdep)
library(tidyverse)
knitr::opts_chunk$set(cache=TRUE)
```


```{r Raw Data,echo=FALSE,warnings=FALSE}
IncomeData <- readr::read_csv('Data/Income_Data.csv') %>%
  mutate(State = case_when(
    State == 'New South Wales' ~ 'NSW',
    State == 'Victoria' ~ 'VIC',
    State == 'Queensland' ~ 'QLD',
    State == 'South Australia' ~ 'SA',
    State == 'Western Australia' ~ 'WA',
    State == 'Tasmania' ~ 'TAS',
    State == 'Northern Territory' ~ 'NT',
    State == 'Australian Capital Territory' ~ 'ACT',
    TRUE ~ as.character(State))) %>% filter(Weekly_Household_Income =="$1,000-$1,249"|Household_Composition == "Total Households")

```
#Analysis

- Number of people for 21 income categories provided for each regions (Histogram for different LGAs   with bins as the income categories)  
- A density plot created using the historgram  
- Compute p= 0.01, 0.02, ....., 0.99 for each LGA

#Analysis

##Table2

#Analysis

```{r, plotData}
Inc_cats <- c("$1-$149","$150-$299","$300-$399",     "$400-$499","$500-$649","$650-$799","$800-$999","$1,000-$1,249", "$1,250-$1,499",  "$1,500-$1,749",  "$1,750-$1,999", "$2,000-$2,499", "$2,500-$2,999", "$3,000-$3,499", "$3,500-$3,999", "$4,000-$4,499",  "$4,500-$4,999",  "$5,000-$5,999", "$6,000-$7,999", "$8,000 or more")

Inc_cats_x <- c(75,225,350,450,575, 725, 900, 1125,1375,1625,1875,2250,2750,3250,3750,4250,4750,5500,7000,9000)

# <- data.frame(Categories = Inc_cats, )

```

```{r, Percentiles for each LGA}

Inc_cats <- c("$1-$149","$150-$299","$300-$399",     "$400-$499","$500-$649","$650-$799","$800-$999","$1,000-$1,249", "$1,250-$1,499",  "$1,500-$1,749",  "$1,750-$1,999", "$2,000-$2,499", "$2,500-$2,999", "$3,000-$3,499", "$3,500-$3,999", "$4,000-$4,499",  "$4,500-$4,999",  "$5,000-$5,999", "$6,000-$7,999", "$8,000 or more")

IncomeData%>%
  mutate(Weekly_Household_Income =  factor(Weekly_Household_Income, levels = Inc_cats)) %>%
  arrange(LGA_2016, Weekly_Household_Income) %>% filter(HHCD_2016=="TOT") -> Income_Data_new

#Removing LGAs for which the sum of values across different income levels is zero
g<-Income_Data_new%>%group_by(LGA_2016)%>%summarize(suml=sum(Value))%>%filter(suml!=0)
Income_Data_new%>%filter(LGA_2016 %in% g$LGA_2016) -> Income_Data_new_2


#Finding the CDF for each LGAs
Income_Data_new_2 %>%group_by(LGA_2016) %>% mutate(CDF = cumsum(Value)/sum(Value)) -> LGA_cumsum

#Splitting Weekly_Income into lower and upper boundary and Correcting the row $8000 and more
LGA_cumsum %>% separate(Weekly_Household_Income,into = c("lb","ub"),sep="-") %>% mutate(lb =ifelse(lb=="$8,000 or more","$8,000",lb))%>% replace_na(list(ub="$9999"))-> LGA_Split


#Removing dollars and converting the lower and upper boundary to numeric vectors
LGA_Split%>% mutate(lb = str_replace_all(lb,'\\$','') )%>% mutate(ub = str_replace_all(ub,'\\$','') ) -> LGA_split_v1

LGA_split_v1%>% mutate(lb = as.numeric(str_replace_all(lb,'\\,','')) )%>% mutate(ub = as.numeric(str_replace_all(ub,'\\,',''))+1 ) -> LGA_split_v2


# Function joining lines between two points in a ECDF for each interval for each LGA(A way to find percentiles from the stepwise cumulative distribution function)
#Each LGA would have number of lines = (No. of intervals - 1)

plines_LGA = function(code)
{
  #subset of LGA_Split_v2
  
  code_row <- which(LGA_split_v2$LGA_2016 == code)
  LGA_split_v2[code_row,] -> CR
  
  
  #plot(LGA_cumsum_Code$Weekly_Household_Income,LGA_cumsum_Code$CDF,type="s",ylim = c(0,1), xlab = "Weekly Household Income")
  
  p = ggplot(CR, aes(x=lb,y=CDF))+ geom_point() + geom_line() + geom_hline(yintercept = seq(0.1,0.9,0.1))
  
  p + scale_x_continuous(name= "Weekly_Income", breaks =       c(1,150,300,400,500,650,800,1000,1250,1500,1750,2000,2500,3000,3500,4000,4500,5000,6000,8000))
  
  slope<- diff(c(0, CR$CDF))/diff(c(0, CR$lb))
  
  intercept<- - CR$lb*slope + CR$CDF 
  
  
  ##########  
  quant.func<- function(y){
    if(y > 1 || y < 0){return(warning('y MUST BE LESS THAN 1!'))}
    if(y == 1){return(x<- CR$lb[length(CR$lb)])}
    else{
      indicator<- sum(y >= c(0, CR$CDF))
      x<- (y - intercept[indicator])/slope[indicator]
      return(x)
    }
  }
  
  y<- seq(0.1, 0.99, length.out = 99)
  code_quantiles <- sapply(1:99, function(i) quant.func(y[i]))
  
  return(code_quantiles)
  
}
code_list <-unique(LGA_split_v2$LGA_2016)
LGA_prcntl_list <- lapply(code_list,plines_LGA)
LGA_prcntl_mat <- matrix(unlist(LGA_prcntl_list),ncol=99,byrow=TRUE)
LGA_prcntl_matv2<-cbind(code_list,LGA_prcntl_mat)
colnames(LGA_prcntl_matv2)<-c("LGA_2016","p1","p2","p3","p4","p5","p6","p7","p8","p9","p10","p11","p12","p13","p14","p15","p16","p17","p18","p19","p20","p21","p22","p23","p24","p25","p26","p27","p28","p29","p30","p31","p32","p33","p34","p35","p36","p37","p38","p39","p40","p41","p42","p43","p44","p45","p46","p47","p48","p49","p50","p51","p52","p53","p54","p55","p56","p57","p58","p59","p60","p61","p62","p63","p64","p65","p66","p67","p68","p69","p70","p71","p72","p73","p74","p75","p76","p77","p78","p79","p80","p81","p82","p83","p84","p85","p86","p87","p88","p89","p90","p91","p92","p93","p94","p95","p96","p97","p98","p99")
```
### LGA by percentile matrix done 


#Reading LGA Data

 - Reading OGR vector maps into Spatial objects
 - The Geospatial Data Abstraction Library (GDAL) is a computer software library for reading and       writing raster and vector geospatial data formats
 - The rgdal package has been around for more than a decade and provides bindings to the incredible    Geospatial Data Abstraction Library (GDAL) for reading, writing and converting between spatial      formats

```{r print-LGA Input,echo=FALSE}
LGAShp <- rgdal::readOGR('../LGA_shapefiles',layer="LGA_2016_AUST")
# for topologically-aware polygon simplification
LGA_subset <- rmapshaper::ms_simplify(LGAShp, keep = 0.05)
save(LGA_subset,file = "../Data/GA_subset.Rda")

#Some LGA codes not in LGAData but present in Income Data
#For which income level are available but no shape file available
#Deleting those LGA codes for the purpose of carrying out further analysis


LGA_data <- LGA_subset@data

LGA_data$id <- row.names(LGA_data)
LGA_data$LGA_CODE16 <- as.integer(as.character(LGA_data$LGA_CODE16))
LGA_data$id <- row.names(LGA_data)
LGA_data$LGA_CODE16 <- as.integer(as.character(LGA_data$LGA_CODE16))
LGA_map <- ggplot2::fortify(LGA_subset)
LGA_map$group <- paste("g",LGA_map$group,sep=".")
LGA_map$piece <- paste("p",LGA_map$piece,sep=".")
```


#HeatMap - Maps with Structural Breaks
```{r print-Heatmap,echo=FALSE}
LGA_data %>%
  dplyr::select(id, LGA_CODE16, LGA_NAME16) %>%
  rename(name = LGA_NAME16) %>%
  right_join(as_tibble(LGA_prcntl_matv2),by=c("LGA_CODE16" = "LGA_2016")) %>%
  right_join(LGA_map)-> LGA_map_Income

gather(LGA_map_Income,Percentile,percentile_values, -c(id,LGA_CODE16,name,long,lat,order,hole,piece,group)) ->LGA_map_Income2

ggplot(LGA_map_Income) + geom_polygon(aes(long, lat, group = group,fill=p1)) + coord_fixed()
ggplot(LGA_map_Income) + geom_polygon(aes(long, lat, group = group,fill=p50)) + coord_fixed()

install.packages("devtools")

# then gganimate
devtools::install_github("dgrtwo/gganimate")

library(gganimate)

Aus <- ggplot(LGA_map_Income2) + geom_polygon(aes(long, lat, group = group,fill=percentile_values,frame=Percentile),color = "white", size = .05) + xlab("Latitude") +
  ylab("Longitude")+ scale_fill_gradient(low = "darkgreen", high = "darkred")+ coord_fixed()

Aus$Percentile <- factor(Aus$Percentile, levels = c(paste0("p", 1:99)) )

#gganimate(Aus)
#gganimate(Aus, interval = 1.5, filename = 'Aus_Economy.mp4')
gganimate(Aus, interval = 1.5, ani.width = 1600, ani.height = 900, filename = 'Aus_Economy3.mp4')


```  

```{r Allcode,echo=FALSE}

#Creating k nearest Neighbours
# knn2nb converts a knn object returned by knearneigh into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids.
coords <-coordinates(LGA_subset)
length(coords)
IDs <- row.names(as(LGA_subset, "data.frame"))
LGA_nn_1 <- knn2nb(knearneigh(coords, k = 1), row.names = IDs)
LGA_nn_2 <- knn2nb(knearneigh(coords, k = 2), row.names = IDs)
LGA_nn_3 <- knn2nb(knearneigh(coords, k = 3), row.names = IDs)
LGA_nn_4 <- knn2nb(knearneigh(coords, k = 4), row.names = IDs)
```

#Plotting nearest neighbors neighbours K=1

```{r,echo=FALSE}
plot(LGA_nn_1,coords)
dsts <- unlist(nbdists(LGA_nn_1, coords,longlat=TRUE))
max_1nn <- max(dsts)
max_1nn
```

#Plotting nearest neighbors neighbours K=2

```{r,echo=FALSE}
plot(LGA_nn_2,coords)
dsts <- unlist(nbdists(LGA_nn_2, coords,longlat=TRUE))
max_1nn <- max(dsts)
max_1nn
```

#Plotting nearest neighbors neighbours K=3

```{r,echo=FALSE}
plot(LGA_nn_3,coords)
dsts <- unlist(nbdists(LGA_nn_3, coords,longlat=TRUE))
max_1nn <- max(dsts)
max_1nn
```

#Plotting nearest neighbors neighbours K=4

```{r,echo=FALSE}
plot(LGA_nn_3,coords)
dsts <- unlist(nbdists(LGA_nn_4, coords,longlat=TRUE))
max_1nn <- max(dsts)
max_1nn
```

```{r,echo=FALSE}
# Checking if the neighbours object is symmetric

nb_list <- list(k1 = LGA_nn_1, k2 = LGA_nn_2, k3=LGA_nn_1, k4 = LGA_nn_1)
sapply(nb_list, function(x) is.symmetric.nb(x, verbose = FALSE,force = TRUE))
#If need be, k-nearest neighbour objects can be made symmetrical using the make.sym.nb function
LGA_nn_1 <- make.sym.nb(LGA_nn_1)

#To calculate a list of vectors of distances
#corresponding to the neighbour object for first nearest neighbours. The
#greatest value will be the minimum distance needed to make sure that all the
#areas are linked to at least one neighbour
dsts <- unlist(nbdists(LGA_nn_1, coords,longlat=TRUE))
summary(dsts)
max_1nn <- max(dsts)
max_1nn

#nb2listw function takes a neighbours list object and converts it into a weights object
#For style="W", the weights vary between unity divided by the largest and
#smallest numbers of neighbours, and the sums of weights for each areal entity
#are unity  
#B is the basic binary coding

Weights_W <- nb2listw(LGA_nn_1,style="W")
Weights_B <- nb2listw(LGA_nn_1,style="B")
Weights_C <- nb2listw(LGA_nn_1,style= "C")
Weights_U <- nb2listw(LGA_nn_1,style="U")
Weights_S <- nb2listw(LGA_nn_1,style="S")

#Weights and Neighbors same as LGA_map1.R
```

#Moran Scatterplot

```{r,echo=FALSE}
Moran_test <-moran.test(LGA_map_Income$p1, Weights_W)
moran.plot(LGA_map_Income$p1, Weights_W)
```        

#Local Moran
```{r,echo=FALSE}
#Local measures of spatial autocorrelation
local_Moran <- localmoran(OneIncome_LGA$Median_Income_LGA, Weights_W)
summary(local_Moran)
```

#Local Significance Plot using Moran's Statistic

```{r,echo=FALSE}
#creating scaled resonse variable
OneIncome_LGA$Median_Income_LGA_s <- scale(OneIncome_LGA$Median_Income_LGA)  %>% as.vector()
# create a spatially lagged variable and save it to a new column
OneIncome_LGA$Median_Income_LGA_s_lag <- scale(lag.listw(Weights_W,OneIncome_LGA$Median_Income_LGA))%>%as.vector()
# summary of variables, to inform the analysis
#summary(OneIncome_LGA$Median_Income_LGA_s)
#summary(OneIncome_LGA$Median_Income_LGA_s_lag)


OneIncome_LGA$local_Moran_stat <- NA

# high-high quadrant
OneIncome_LGA[(OneIncome_LGA$Median_Income_LGA_s >= 0 & 
                 OneIncome_LGA$Median_Income_LGA_s_lag >= 0) & 
                (local_Moran[, 5] <= 0.05), "local_Moran_stat"] <- "high-high"
# low-low quadrant

OneIncome_LGA[(OneIncome_LGA$Median_Income_LGA_s <= 0 & 
                 OneIncome_LGA$Median_Income_LGA_s_lag <= 0) & 
                (local_Moran[, 5] <= 0.05), "local_Moran_stat"] <- "low-low"

# high-low quadrant

OneIncome_LGA[(OneIncome_LGA$Median_Income_LGA_s >= 0 & 
                 OneIncome_LGA$Median_Income_LGA_s_lag  <= 0) & 
                (local_Moran[, 5] <= 0.05), "local_Moran_stat"] <- "high-low"

# low-high quadrant

OneIncome_LGA[(OneIncome_LGA$Median_Income_LGA_s <= 0 & 
                 OneIncome_LGA$Median_Income_LGA_s_lag >= 0) & 
                (local_Moran[, 5] <= 0.05), "local_Moran_stat"] <- "low-high"


# non-significant observations
OneIncome_LGA[(local_Moran[, 5] > 0.05), "local_Moran_stat"] <- "not signif."  


OneIncome_LGA %>% 
  group_by(local_Moran_stat) %>% 
  tally()
```

#Local Significance Plot using Moran's Statistic

```{r,echo=FALSE}
# plotting the map for local_Morans
df_OneIncome <- fortify(OneIncome_LGA, region="LGA_2016")
df_OneIncome %>% right_join(OneIncome_LGA) %>%right_join(LGA_data,by=c("LGA_2016"="LGA_CODE16")) %>% right_join(LGA_map)-> LGA_OneIncome

LGA_OneIncome %>% 
  ggplot(aes(long, lat, group = group, fill = local_Moran_stat)) + 
  geom_polygon(color = "white", size = .05)  + coord_equal() + 
  theme_void() + scale_fill_brewer( palette = "Set1") +coord_fixed()
```

#Local Significance Plot using Gi star Statistic

```{r,echo=FALSE,warning=FALSE}
#G and Gstar local spatial statistics
local_G <-localG(OneIncome_LGA$Median_Income_LGA, Weights_W)
summary(local_G)

local_G_new<- NA

local_G_new[local_G >= 1.96] <- "high-high"
local_G_new[(local_G <= -1.96)] <- "low-low"
local_G_new[(-1.96<local_G)& (local_G<1.96)] <- "not_signif."

LGA_OneIncome_r=cbind(OneIncome_LGA,local_G_new)

LGA_OneIncome_r %>% 
  group_by(local_G_new) %>% 
  tally()
```

#Local Significance Plot using Gi star Statistic

```{r,echo=FALSE,warning=FALSE}
# plotting the map
df_Gstar_OneIn <- fortify(LGA_OneIncome_r, region="LGA_2016")

df_Gstar_OneIn %>% right_join(OneIncome_LGA) %>%right_join(LGA_data,by=c("LGA_2016"="LGA_CODE16")) %>% right_join(LGA_map)-> LGA_OneIncome_Gstar

LGA_OneIncome_Gstar %>% 
  ggplot(aes(long, lat, group = group, fill = local_G_new)) + 
  geom_polygon(color = "white", size = .05)  + coord_equal() + 
  theme_void() + scale_fill_brewer( palette = "Set1")+ coord_fixed()
```

#Regions spatially significant in local Moran and not in local Gi star 

```{r,echo=FALSE}
#LGA_map_4 %>% filter(local_Moran_stat == c(""high-high","low-low"))
##LGA where local Moran stat is significant and high high
LGA_OneIncome_Gstar %>% 
  group_by(local_Moran_stat,LGA_NAME16,STE_NAME16) %>% filter(local_Moran_stat=="high-high") %>% tally() ->Moran_High_High

LGA_OneIncome_Gstar %>% 
  group_by(local_Moran_stat,LGA_NAME16,STE_NAME16) %>% filter(local_Moran_stat=="low-low")%>%tally()->Moran_low_low
##LGA where local  G stat is significant and high high
LGA_OneIncome_Gstar %>% 
  group_by(local_G_new,LGA_NAME16,STE_NAME16) %>% filter(local_G_new=="high-high")%>%tally()->G_High_High


LGA_OneIncome_Gstar %>% 
  group_by(local_G_new,LGA_NAME16,STE_NAME16) %>% filter(local_G_new=="low-low") %>%tally()->G_low_low

#spatially significant in local Moran but not in local Gi
Moran_not_G = setdiff(Moran_High_High$LGA_NAME16,G_High_High$LGA_NAME16)
kable(Moran_not_G,longtable=TRUE)
```

#Regions spatially significant in local Moran and not in local Gi star 

```{r,echo=FALSE}
G_not_Moran = setdiff(G_High_High$LGA_NAME16,Moran_High_High$LGA_NAME16)
kable(G_not_Moran,longtable=TRUE)
```
